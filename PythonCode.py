# -*- coding: utf-8 -*-
"""Final working cs685

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qQXJS14D1g8jAjxHm0DiwDqk77HkWIh6
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

df_train = pd.read_csv(
    "/content/drive/MyDrive/drug_review_dataset_drugs_com/drugsComTrain_raw.csv/drugsComTrain_raw.csv",
    parse_dates=["date"],
    date_format="%d-%b-%y"
)

df_test = pd.read_csv(
    "/content/drive/MyDrive/drug_review_dataset_drugs_com/drugsComTest_raw.csv/drugsComTest_raw.csv",
    parse_dates=["date"],
    date_format="%d-%b-%y"
)

print("Train shape :" ,df_train.shape)
print("Test shape :", df_test.shape)

df_train.head(10)

#checking if there are not more than one reviews per patient

print("unique values count of train : " ,len(set(df_train['uniqueID'].values)))
print("length of train : " ,df_train.shape[0])

# Combine the datasets
df_all = pd.concat([df_train, df_test])



# describing the combined dataset

df_all.describe()

# taking out information from the data
df_all.info()

# get the datatype of columns
df_all.dtypes

# checking if the data contains any NULL values
df_all.isnull().any()

# Calculate the number of unique drugs per condition
condition_dn = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)

# Create the plot
fig, ax = plt.subplots(figsize=(14, 6))
condition_dn[0:20].plot(kind="bar", ax=ax, color="green", fontsize=10)
ax.set_xlabel("Condition", fontsize=20)
ax.set_ylabel("Number of Unique Drugs", fontsize=20)
ax.set_title("Top 20: The Number of Drugs per Condition", fontsize=20)
plt.show()

#We see there are more than 200 number of unique drugs for the condition of Pain.

# Top 10 drugs which are used for the top condition, that is Pain

df1 = df_all[df_all['condition'] == 'Pain']['drugName'].value_counts()[0: 20]
sns.set(font_scale = 1.2, style = 'darkgrid')

sns_ = sns.barplot(x = df1.index, y = df1.values, palette = 'summer')
sns_.set_xlabel('Drug Names')
sns_.set_title("Top 20 Drugs used for Pain")
plt.setp(sns_.get_xticklabels(), rotation = 90);

#the least recommended drugs were only recommeded once
#"users found this comment useful" appears in the condition, which seems like an error in the crawling process
#harshit we are doing the same thing in the next cell as well, delete this one i guess
condition_dn = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)

condition_dn[condition_dn.shape[0]-20:condition_dn.shape[0]].plot(kind="bar", figsize = (14,6), fontsize = 10,color="green")
plt.xlabel("", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Bottom20 : The number of drugs per condition.", fontsize = 20)



# inspecting the condition "users found this comment helpful"
df_all[df_all['condition']=='3</span> users found this comment helpful.'].head(10)

# Calculate the number of unique drugs per condition
condition_dn = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)

# Plot the bottom 20 conditions with the fewest unique drugs
fig, ax = plt.subplots(figsize=(14, 6))
condition_dn.tail(20).plot(kind="bar", ax=ax, color="green", fontsize=10)
ax.set_xlabel("Condition", fontsize=20)
ax.set_ylabel("Number of Unique Drugs", fontsize=20)
ax.set_title("Bottom 20: The Number of Drugs per Condition", fontsize=20)
plt.show()

# This barplot shows the top 20 drugs with the 10/10 rating

# Setting the Parameter
sns.set(font_scale = 1.2, style = 'darkgrid')
plt.rcParams['figure.figsize'] = [15, 8]

rating = dict(df_all.loc[df_all.rating == 10, "drugName"].value_counts())
drugname = list(rating.keys())
drug_rating = list(rating.values())

sns_rating = sns.barplot(x = drugname[0:20], y = drug_rating[0:20])

sns_rating.set_title('Top 20 drugs with 10/10 rating')
sns_rating.set_ylabel("Number of Ratings")
sns_rating.set_xlabel("Drug Names")
plt.setp(sns_rating.get_xticklabels(), rotation=90);

# This barplot shows the Top 20 drugs with the 1/10 rating

# Setting the Parameter
sns.set(font_scale = 1.2, style = 'darkgrid')
plt.rcParams['figure.figsize'] = [15, 8]

rating = dict(df_all.loc[df_all.rating == 1, "drugName"].value_counts())
drugname = list(rating.keys())
drug_rating = list(rating.values())

sns_rating = sns.barplot(x = drugname[0:20], y = drug_rating[0:20], palette = 'winter')

sns_rating.set_title('Top 20 drugs with 1/10 rating')
sns_rating.set_ylabel("Number of Ratings")
sns_rating.set_xlabel("Drug Names")
plt.setp(sns_rating.get_xticklabels(), rotation=90);

# making a donut chart to represent share of each ratings
#The rating of 10 is more than twice as many as the others.
size = [68005, 46901, 36708, 25046, 12547, 10723, 8462, 6671]
colors = ['pink', 'cyan', 'maroon',  'magenta', 'orange', 'navy', 'lightgreen', 'yellow']
labels = "10", "1", "9", "8", "7", "5", "6", "4"

my_circle = plt.Circle((0, 0), 0.7, color = 'white')

plt.rcParams['figure.figsize'] = (10, 10)
plt.pie(size, colors = colors, labels = labels, autopct = '%.2f%%')
plt.axis('off')
plt.title('Pie Chart Representation of Ratings', fontsize = 25)
p = plt.gcf()
plt.gca().add_artist(my_circle)
plt.legend()
plt.show()



# checking a review
df_train['review'][1]

df_train['review'][2]

#word cloud for the reviews with some custom stopwords.
from wordcloud import WordCloud, STOPWORDS

def plot_wordcloud(text, mask=None, max_words=250, max_font_size=100, figure_size=(24.0,16.0),
                   title = None, title_size=40, image_color=False):
    stopwords = set(STOPWORDS)
    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}
    stopwords = stopwords.union(more_stopwords)

    wordcloud = WordCloud(background_color='white',
                    stopwords = stopwords,
                    max_words = max_words,
                    max_font_size = max_font_size,
                    random_state = 42,
                    width=800,
                    height=400,
                    mask = mask)
    wordcloud.generate(str(text))

    plt.figure(figsize=figure_size)
    if image_color:
        image_colors = ImageColorGenerator(mask);
        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation="bilinear");
        plt.title(title, fontdict={'size': title_size,
                                  'verticalalignment': 'bottom'})
    else:
        plt.imshow(wordcloud);
        plt.title(title, fontdict={'size': title_size, 'color': 'black',
                                  'verticalalignment': 'bottom'})
    plt.axis('off');
    plt.tight_layout()

plot_wordcloud(df_all["review"], title="Word Cloud of review")

# let's make a new column review sentiment
# If the rating is 5 or above(below), assign 'Sentiment' as positive(negative).

df_all.loc[(df_all['rating'] >= 5), 'Sentiment'] = 1
df_all.loc[(df_all['rating'] < 5), 'Sentiment'] = 0

df_all['Sentiment'].value_counts()

# a pie chart to represent the sentiments of the patients

size = [161491, 53572]
colors = ['lightblue', 'navy']
labels = "Positive Sentiment","Negative Sentiment"
explode = [0, 0.1]

plt.rcParams['figure.figsize'] = (10, 10)
plt.pie(size, colors = colors, labels = labels, explode = explode, autopct = '%.2f%%')
plt.axis('off')
plt.title('Pie Chart Representation of Sentiments', fontsize = 25)
plt.legend()
plt.show()

# making Words cloud for the postive sentiments

positive_sentiments = " ".join([text for text in df_all['review'][df_all['Sentiment'] == 1]])

from wordcloud import WordCloud
from wordcloud import STOPWORDS

stopwords = set(STOPWORDS)
wordcloud = WordCloud(background_color = 'magenta', stopwords = stopwords, width = 1200, height = 800).generate(positive_sentiments)

plt.rcParams['figure.figsize'] = (15, 15)
plt.title('Word Cloud of Positive Reviews', fontsize = 30)
print(wordcloud)
plt.axis('off')
plt.imshow(wordcloud)
plt.show()

# making wordscloud for the Negative sentiments

negative_sentiments = " ".join([text for text in df_all['review'][df_all['Sentiment'] == 0]])

from wordcloud import WordCloud
from wordcloud import STOPWORDS

stopwords = set(STOPWORDS)
wordcloud = WordCloud(background_color = 'cyan', stopwords = stopwords, width = 1200, height = 800).generate(negative_sentiments)

plt.rcParams['figure.figsize'] = (15, 15)
plt.title('Word Cloud of Negative Reviews', fontsize = 30)
print(wordcloud)
plt.axis('off')
plt.imshow(wordcloud)
plt.show()

df_all.head()

from collections import defaultdict
df_all_6_10 = df_all[df_all["rating"]>5]
df_all_1_5 = df_all[df_all["rating"]<6]

# Generate and compare word frequency plots for positive (6-10) and negative (1-5) reviews using 1-gram.

import plotly.graph_objects as go
from plotly.subplots import make_subplots
from collections import defaultdict
import pandas as pd


## Custom function for n-gram generation ##
def generate_ngrams(text, n_gram=1):
    token = [token for token in text.lower().split(" ") if token != "" if token not in STOPWORDS]
    ngrams = zip(*[token[i:] for i in range(n_gram)])
    return [" ".join(ngram) for ngram in ngrams]

## Custom function for horizontal bar chart ##
def horizontal_bar_chart(df, color):
    trace = go.Bar(
        y=df["word"].values[::-1],
        x=df["wordcount"].values[::-1],
        showlegend=False,
        orientation='h',
        marker=dict(color=color),
    )
    return trace

# Frequency dictionary and plotting for ratings 1 to 5
freq_dict_1_5 = defaultdict(int)
for sent in df_all_1_5["review"]:
    for word in generate_ngrams(sent):
        freq_dict_1_5[word] += 1
fd_sorted_1_5 = pd.DataFrame(sorted(freq_dict_1_5.items(), key=lambda x: x[1], reverse=True))
fd_sorted_1_5.columns = ["word", "wordcount"]
trace0 = horizontal_bar_chart(fd_sorted_1_5.head(50), 'blue')

# Frequency dictionary and plotting for ratings 6 to 10
freq_dict_6_10 = defaultdict(int)
for sent in df_all_6_10["review"]:
    for word in generate_ngrams(sent):
        freq_dict_6_10[word] += 1
fd_sorted_6_10 = pd.DataFrame(sorted(freq_dict_6_10.items(), key=lambda x: x[1], reverse=True))
fd_sorted_6_10.columns = ["word", "wordcount"]
trace1 = horizontal_bar_chart(fd_sorted_6_10.head(50), 'green')

# Creating two subplots
fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.1,
                    subplot_titles=["Frequent words of rating 1 to 5",
                                    "Frequent words of rating 6 to 10"])

fig.add_trace(trace0, row=1, col=1)
fig.add_trace(trace1, row=1, col=2)
fig.update_layout(height=800, width=500, paper_bgcolor='rgb(233,233,233)', title="Word Count Plots")
fig.show()

# Generate and compare word frequency plots for positive (6-10) and negative (1-5) reviews using bi-grams.

freq_dict = defaultdict(int)
for sent in df_all_1_5["review"]:
    for word in generate_ngrams(sent,2):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace1 = horizontal_bar_chart(fd_sorted.head(50), 'orange')

freq_dict = defaultdict(int)
for sent in df_all_6_10["review"]:
    for word in generate_ngrams(sent,2):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace2 = horizontal_bar_chart(fd_sorted.head(50), 'orange')

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Assuming trace1 and trace2 are defined

# Creating two subplots
fig = make_subplots(
    rows=1, cols=2,
    vertical_spacing=0.04,
    horizontal_spacing=0.15,
    subplot_titles=["Frequent bigrams of rating 1 to 5",
                    "Frequent bigrams of rating 6 to 10"]
)

fig.add_trace(trace1, row=1, col=1)
fig.add_trace(trace2, row=1, col=2)
fig.update_layout(
    height=1200,
    width=1000,
    paper_bgcolor='rgb(233,233,233)',
    title="Bigram Count Plots"
)
fig.show()

# Generate and compare word frequency plots for positive (6-10) and negative (1-5) reviews using tri-grams.


freq_dict = defaultdict(int)
for sent in df_all_1_5["review"]:
    for word in generate_ngrams(sent,3):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace1 = horizontal_bar_chart(fd_sorted.head(50), 'green')

freq_dict = defaultdict(int)
for sent in df_all_6_10["review"]:
    for word in generate_ngrams(sent,3):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace2 = horizontal_bar_chart(fd_sorted.head(50), 'green')

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Assuming trace1 and trace2 are defined and contain the trigram data

# Creating two subplots
fig = make_subplots(
    rows=1, cols=2,
    vertical_spacing=0.04,
    horizontal_spacing=0.15,
    subplot_titles=["Frequent trigrams of rating 1 to 5",
                    "Frequent trigrams of rating 6 to 10"]
)

fig.add_trace(trace1, row=1, col=1)
fig.add_trace(trace2, row=1, col=2)
fig.update_layout(
    height=1200,
    width=1600,
    paper_bgcolor='rgb(233,233,233)',
    title="Trigram Count Plots"
)
fig.show()

# Generate and compare word frequency plots for positive (6-10) and negative (1-5) reviews using 4-grams.

freq_dict = defaultdict(int)
for sent in df_all_1_5["review"]:
    for word in generate_ngrams(sent,4):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace1 = horizontal_bar_chart(fd_sorted.head(50), 'red')

freq_dict = defaultdict(int)
for sent in df_all_6_10["review"]:
    for word in generate_ngrams(sent,4):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace2 = horizontal_bar_chart(fd_sorted.head(50), 'red')

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# trace1 and trace2 are defined and contain the 4-gram data

# Creating two subplots
fig = make_subplots(
    rows=1, cols=2,
    vertical_spacing=0.04,
    horizontal_spacing=0.15,
    subplot_titles=["Frequent 4-grams of rating 1 to 5",
                    "Frequent 4-grams of rating 6 to 10"]
)

fig.add_trace(trace1, row=1, col=1)
fig.add_trace(trace2, row=1, col=2)
fig.update_layout(
    height=1200,
    width=1600,
    paper_bgcolor='rgb(233,233,233)',
    title="4-grams Count Plots"
)
fig.show()

#We can see that 4-gram classifies emotions much betther than grams. Therefore, 4-gram was used to build deep learning model.

df_all.head()

rating = df_all['rating'].value_counts().sort_index()  # Sort by index to keep ratings in order
rating.plot(kind="bar", figsize=(14, 6), fontsize=10, color="green")
plt.xlabel("Rating", fontsize=20)  # Set x-axis label to "Rating"
plt.ylabel("Count", fontsize=20)  # Set y-axis label to "Count"
plt.title("Count of Rating Values", fontsize=20)
plt.show()

#Patients rate 10, 9, 1, 8 a lot more meaning their reactions are extreme and a majority of the time positive.

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

cnt_srs = df_all['date'].dt.year.value_counts()
cnt_srs = cnt_srs.sort_index()

plt.figure(figsize=(14, 6))
sns.barplot(x=cnt_srs.index, y=cnt_srs.values, alpha=0.8, color='green')  # Use x and y parameters
plt.xticks(rotation='vertical')
plt.xlabel('Year', fontsize=12)
plt.ylabel('Number of Reviews', fontsize=12)  # Added label for y-axis
plt.title("Number of Reviews by Year", fontsize=14)
plt.show()

#The number of reviews increased significantly from 2014, peaking in 2016, before declining in 2017.

df_all['year'] = df_all['date'].dt.year
rating = df_all.groupby('year')['rating'].mean()
rating.plot(kind="bar", figsize = (14,6), fontsize = 10,color="green")
plt.xlabel("", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Mean rating in year", fontsize = 20)

#increase in the number of reviews along the years normalized the ratings

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df_all is already defined and contains the 'date' column
cnt_srs = df_all['date'].dt.month.value_counts()
cnt_srs = cnt_srs.sort_index()

plt.figure(figsize=(14, 6))
sns.barplot(x=cnt_srs.index, y=cnt_srs.values, alpha=0.8, color='green')  # Use x and y parameters
plt.xticks(rotation='vertical')
plt.xlabel('Month', fontsize=12)
plt.ylabel('Number of Reviews', fontsize=12)  # Added label for y-axis
plt.title("Number of Reviews by Month", fontsize=14)
plt.show()

#Interestingly, the average rating differed by year but it is similar by month.

df_all['month'] = df_all['date'].dt.month
rating = df_all.groupby('month')['rating'].mean()
rating.plot(kind="bar", figsize = (14,6), fontsize = 10,color="green")
plt.xlabel("", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Mean rating in month", fontsize = 20)

#We checked maybe the day of the week affected the ratings like the salary day, but it did not make much difference.

df_all['day'] = df_all['date'].dt.day
rating = df_all.groupby('day')['rating'].mean()
rating.plot(kind="bar", figsize = (14,6), fontsize = 10,color="green")
plt.xlabel("", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Mean rating in day", fontsize = 20)

plt.figure(figsize=(14, 6))
sns.histplot(df_all["usefulCount"].dropna(), color="green", kde=True)  # Adjust bin size for more detail
plt.xlabel("Useful Count", fontsize=12)  # Adding x-axis label
plt.ylabel("Density", fontsize=12)       # Adding y-axis label for clarity
plt.title("Distribution of usefulCount", fontsize=16)

# Limiting y-axis to 0-10000
plt.ylim(0, 10000)

plt.show()
#the more people read the review no matter their contents are good or bad, which makes the usefulcount very high.
#we normalize it by conditions, considering people's accessibility.

df_all["usefulCount"].describe()

percent = (df_all.isnull().sum()).sort_values(ascending=False)
percent.plot(kind="bar", figsize = (14,6), fontsize = 10, color='green')
plt.xlabel("Columns", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Total Missing Value ", fontsize = 20)

print("Missing value (%):", 1200/df_all.shape[0] *100)
#We will delete this because the percentage is lower than 1%.

df_all.head()

# Data Preprocessing



# df_train = df_train.dropna(axis=0)
df_all = df_all.dropna(axis=0).reset_index()
# df_all = pd.concat([df_train,df_test]).reset_index()
# del df_all['index']
percent = (df_all.isnull().sum()).sort_values(ascending=False)
percent.plot(kind="bar", figsize = (14,6), fontsize = 10, color='green')
plt.xlabel("Columns", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Total Missing Value ", fontsize = 20)

#Missing Values Removed

# removing  rows where </span> is present i condition column
all_list = set(df_all.index)
span_list = []
for i,j in enumerate(df_all['condition']):
    if '</span>' in j:
        span_list.append(i)

new_idx = all_list.difference(set(span_list))
df_all = df_all.iloc[list(new_idx)].reset_index()
del df_all['index']

condition_dn = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)

condition_dn[condition_dn.shape[0]-20:condition_dn.shape[0]].plot(kind="bar", figsize = (14,6), fontsize = 10,color="green")
plt.xlabel("", fontsize = 20)
plt.ylabel("", fontsize = 20)
plt.title("Bottom20 : The number of drugs per condition.", fontsize = 20)

# removing the condition which have only one review
df_condition = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)
df_condition = pd.DataFrame(df_condition).reset_index()
df_condition.tail(20)

df_condition_1 = df_condition[df_condition['drugName']==1].reset_index()
df_condition_1['condition'][0:10]

all_list = set(df_all.index)
condition_list = []
for i,j in enumerate(df_all['condition']):
    for c in list(df_condition_1['condition']):
        if j == c:
            condition_list.append(i)

new_idx = all_list.difference(set(condition_list))
df_all = df_all.iloc[list(new_idx)].reset_index()
del df_all['index']

# Remove entries for conditions with only one unique drug.

"""Processing the reviews"""

from bs4 import BeautifulSoup
import nltk
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
nltk.download('stopwords')

df_all.head()

stops = set(stopwords.words('english'))
#stops

#word cloud of stopwords
from wordcloud import WordCloud, STOPWORDS

def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0),
                   title = None, title_size=40, image_color=False):
    stopwords = set(STOPWORDS)
    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}
    stopwords = stopwords.union(more_stopwords)

    wordcloud = WordCloud(background_color='white',
                    stopwords = stopwords,
                    max_words = max_words,
                    max_font_size = max_font_size,
                    random_state = 42,
                    width=800,
                    height=400,
                    mask = mask)
    wordcloud.generate(str(text))

    plt.figure(figsize=figure_size)
    if image_color:
        image_colors = ImageColorGenerator(mask);
        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation="bilinear");
        plt.title(title, fontdict={'size': title_size,
                                  'verticalalignment': 'bottom'})
    else:
        plt.imshow(wordcloud);
        plt.title(title, fontdict={'size': title_size, 'color': 'black',
                                  'verticalalignment': 'bottom'})
    plt.axis('off');
    plt.tight_layout()

plot_wordcloud(stops, title="Word Cloud of stops")

not_stop = ["aren't","couldn't","didn't","doesn't","don't","hadn't","hasn't","haven't","isn't","mightn't","mustn't","needn't","no","nor","not","shan't","shouldn't","wasn't","weren't","wouldn't"]
for i in not_stop:
    stops.remove(i)

#There might be many words that include not, like needn't. These words are important parts of emotional analysis, so we will remove them from stopwords.

df_all.head()

from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import TruncatedSVD
import lightgbm as lgb

import pandas as pd
from bs4 import BeautifulSoup
import re
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

# Keras imports
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D
from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D
from tensorflow.keras.models import Model
from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers

df_all.head()

# Commented out IPython magic to ensure Python compatibility.
#cleaning the reviews

from bs4 import BeautifulSoup
import re
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
import pandas as pd

# Initialize the stemmer and stopwords list once outside the function for efficiency
stemmer = SnowballStemmer('english')

def review_to_words(raw_review):
    """
    Preprocesses a raw review string by removing HTML tags, non-letter characters,
    stopwords, and applying stemming. Returns a cleaned, single string of processed words.
    """
    #Remove HTML tags using BeautifulSoup
    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()

    # Convert to lowercase
    lower = review_text.lower()

    # Replace common HTML codes
    lower = re.sub("&#039;", "", lower)

    # Remove special characters, non-ASCII characters, extra spaces, and trailing/leading whitespace
    lower = re.sub(r'[^\w\d\s]', ' ', lower)
    lower = re.sub(r'[^\x00-\x7F]+', ' ', lower)
    lower = re.sub(r'\s+', ' ', lower).strip()
    lower = re.sub(r'\.{2,}', ' ', lower)

    # Remove stopwords and apply stemming
    words = lower.split()
    meaningful_words = [stemmer.stem(word) for word in words if word not in stops]

    # Join the words back into a single string separated by spaces
    return ' '.join(meaningful_words)


# Measure execution time and apply the function to the 'review' column in df_all
# %time df_all['review_clean'] = df_all['review'].apply(review_to_words)



df_all.head()



"""Model"""



"""Deep Learning Model"""

import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation
from tensorflow.keras.utils import Sequence
import tensorflow as tf

# splitting training and testing data 70%-30%
# df_all is the dataframe that contains 'review_clean' and 'sentiment'
df_train, df_test = train_test_split(df_all, test_size=0.3, random_state=42)

# set up the CountVectorizer
vectorizer = CountVectorizer(analyzer='word',
                             tokenizer=None,
                             preprocessor=None,
                             stop_words=None,
                             min_df=2,
                             ngram_range=(4, 4),
                             max_features=20000)

# Fitting the vectorizer on the clean reviews on the training data
vectorizer.fit(df_train['review_clean'])

# Defining the Dataset Generator Class
class TextDatasetGenerator(Sequence):
    def __init__(self, data, labels, vectorizer, batch_size=64, shuffle=True):
        self.data = data
        self.labels = labels
        self.vectorizer = vectorizer
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(self.data))
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.data) / self.batch_size))

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]
        batch_data = [self.data.iloc[i] for i in batch_indexes]
        batch_labels = self.labels.iloc[batch_indexes]

        # Transform the batch data using the fitted vectorizer
        batch_features = self.vectorizer.transform(batch_data)

        # Convert dense matrix to sparse tensor
        sparse_tensor = tf.sparse.from_dense(batch_features.toarray())

        return sparse_tensor, batch_labels

# Initialize the Dataset Generators
train_generator = TextDatasetGenerator(df_train['review_clean'], df_train['Sentiment'], vectorizer)
test_generator = TextDatasetGenerator(df_test['review_clean'], df_test['Sentiment'], vectorizer)

# Path to save/load the model
model_path = '/content/drive/MyDrive/drug_review_dataset_drugs_com/deep_sentiment_model.h5'

# Step 5: Define the Model (only if not already trained)
if os.path.exists(model_path):
    # Load the model if it exists
    model = load_model(model_path)
    print("Model loaded from disk.")
else:
    #training the model
    model = Sequential([
        Dense(200, input_shape=(20000,)),
        BatchNormalization(),
        Activation('relu'),
        Dropout(0.5),
        Dense(300),
        BatchNormalization(),
        Activation('relu'),
        Dropout(0.5),
        Dense(100, activation='relu'),
        Dense(1, activation='sigmoid')
    ])

    #Compile the Model
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.summary()

    # Train the Model using the Generator
    hist = model.fit(train_generator, epochs=10, verbose=1)

    # Save the trained model
    model.save(model_path)
    print("Model saved to disk.")

  # Plot Training Loss and Accuracy
    import matplotlib.pyplot as plt

    fig, loss_ax = plt.subplots()
    acc_ax = loss_ax.twinx()
    loss_ax.set_ylim([0.0, 1.0])
    acc_ax.set_ylim([0.0, 1.0])

    loss_ax.plot(hist.history['loss'], 'y', label='train loss')
    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')

    loss_ax.set_xlabel('epoch')
    loss_ax.set_ylabel('loss')
    acc_ax.set_ylabel('accuracy')

    loss_ax.legend(loc='upper left')
    acc_ax.legend(loc='lower left')

    plt.show()

# Evaluate the Model on the Test Set
loss_and_metrics = model.evaluate(test_generator, batch_size=32)
print('Test loss and metrics:', loss_and_metrics)

# Get predictions on the test set
predictions = model.predict(test_generator)
sub_preds_deep = predictions

# Convert probabilities to class labels (0 or 1) based on a threshold of 0.5
predicted_labels = (predictions > 0.5).astype(int)

# we can now compare the predicted labels to the true labels from the test set
true_labels = df_test['Sentiment'].values

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt

# Confusion Matrix
cm = confusion_matrix(true_labels, predicted_labels)
print("Confusion Matrix:")
print(cm)

# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f"Accuracy: {accuracy:.2f}")

# F1 Score
f1 = f1_score(true_labels, predicted_labels, average='weighted')  # Adjust 'average' as needed
print(f"F1 Score: {f1:.2f}")

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()



"""Lightgbm"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from sklearn.metrics import confusion_matrix, accuracy_score
from lightgbm import early_stopping

#

target = df_train['Sentiment']
feats = ['usefulCount']

sub_preds = np.zeros(df_test.shape[0])

# Split the data into train and validation sets
trn_x, val_x, trn_y, val_y = train_test_split(df_train[feats], target, test_size=0.2, random_state=42)

feature_importance_df = pd.DataFrame()

# Initialize the classifier
clf = lgb.LGBMClassifier(
        n_estimators=10000,
        learning_rate=0.05,
        num_leaves=30,
        subsample=0.9,
        max_depth=7,
        reg_alpha=0.1,
        reg_lambda=0.1,
        min_split_gain=0.01,
        min_child_weight=2,
        verbosity=-1,  # Use verbosity for logging, -1 to suppress output
)

# Fit the model with early stopping and evaluation set
clf.fit(trn_x, trn_y,
        eval_set=[(val_x, val_y)],
        # Evaluation metric (binary classification, logloss is common)
        callbacks=[early_stopping(stopping_rounds=100, verbose=100)],  # Use callbacks for early stopping
        )  # Set the verbosity level for training

# Predict using the trained model
sub_preds = clf.predict(df_test[feats])

# # Optionally, evaluate the model performance
# print("Confusion Matrix:")
# print(confusion_matrix(val_y, clf.predict(val_x)))
# print("Accuracy:", accuracy_score(val_y, clf.predict(val_x)))

# # Optionally, get feature importances if needed
# feature_importance_df['feature'] = trn_x.columns
# feature_importance_df['importance'] = clf.feature_importances_
# print("Feature Importances:")
# print(feature_importance_df)

solution = df_test['Sentiment']

# Confusion Matrix
cm = confusion_matrix(y_pred = sub_preds, y_true = solution)
print("Confusion Matrix:")
print(cm)

# Accuracy
accuracy = accuracy_score(sub_preds, solution)
print(f"Accuracy: {accuracy:.2f}")

# F1 Score
f1 = f1_score(sub_preds, solution, average='weighted')  # Adjust 'average' as needed
print(f"F1 Score: {f1:.2f}")


# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

del df_all

df_all = pd.concat([df_train, df_test], axis=0)

df_all.shape

from textblob import TextBlob
from nltk.corpus import stopwords
from collections import Counter
import warnings; warnings.simplefilter('ignore')
import nltk
import string
from nltk import ngrams
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
from tqdm import tqdm

def sentiment(review):
    # Sentiment polarity of the reviews with progress tracking
    pol = []
    for i in tqdm(review, desc="Processing Reviews"):
        analysis = TextBlob(i)
        pol.append(analysis.sentiment.polarity)
    return pol

df_all['sentiment_value'] = sentiment(df_all['review'])

df_all['sentiment_clean'] = sentiment(df_all['review_clean'])

def review_basic_cleaning(review):
    # changing to lower case
    lower = review.str.lower()

    # Replacing the repeating pattern of &#039;
    pattern_remove = lower.str.replace("&#039;", "", regex=False)

    # Removing all the special characters
    special_remove = pattern_remove.str.replace(r'[^\w\d\s]', ' ', regex=True)

    # Removing all the non-ASCII characters
    ascii_remove = special_remove.str.replace(r'[^\x00-\x7F]+', ' ', regex=True)

    # Removing leading and trailing whitespaces
    whitespace_remove = ascii_remove.str.replace(r'^\s+|\s+$', '', regex=True)

    # Replacing multiple spaces with a single space
    multiw_remove = whitespace_remove.str.replace(r'\s+', ' ', regex=True)

    # Replacing two or more dots with a single space
    dataframe = multiw_remove.str.replace(r'\.{2,}', ' ', regex=True)

    return dataframe

# Cleaning the reviews without removing the stop words and using snowball stemmer
df_all['review_clean_ss'] = review_basic_cleaning(df_all['review'])
df_all['sentiment_clean_ss'] = sentiment(df_all['review_clean_ss'])

df_all.head()

import string

#Sentence length
df_all['count_sent']=df_all["review"].apply(lambda x: len(re.findall("\n",str(x)))+1)

#Word count in each review
df_all['count_word']=df_all["review_clean"].apply(lambda x: len(str(x).split()))

#Unique word count
df_all['count_unique_word']=df_all["review_clean"].apply(lambda x: len(set(str(x).split())))

#Letter count
df_all['count_letters']=df_all["review_clean"].apply(lambda x: len(str(x)))

#punctuation count
df_all["count_punctuations"] = df_all["review"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))

#upper case words count
df_all["count_words_upper"] = df_all["review"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))

#title case words count
df_all["count_words_title"] = df_all["review"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))

#Number of stopwords
df_all["count_stopwords"] = df_all["review"].apply(lambda x: len([w for w in str(x).lower().split() if w in stops]))

#Average length of the words
df_all["mean_word_len"] = df_all["review_clean"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))

df_all.head()

df_all.columns

df_all.dtypes

# Converting 'year', 'month', and 'day' columns to int64
df_all['year'] = df_all['year'].astype('int64')
df_all['month'] = df_all['month'].astype('int64')
df_all['day'] = df_all['day'].astype('int64')

# Correlation Heatmap of the features engineered
plt.rcParams['figure.figsize'] = [12,8]
sns.set(font_scale = 0.7)
corr = df_all.select_dtypes(include = 'int64').corr()
sns_ = sns.heatmap(corr, annot = True, cmap = 'Wistia')
plt.setp(sns_.get_xticklabels(), rotation = 45);

# Assuming df is your DataFrame
# df_all.to_pickle("/content/drive/MyDrive/drug_review_dataset_drugs_com/df_all.pkl")
# Loading the DataFrame
# df_all = pd.read_pickle("/content/drive/MyDrive/drug_review_dataset_drugs_com/df_all.pkl")

df_all.head()



# Label Encoding Drugname and Conditions
from sklearn.preprocessing import LabelEncoder
label_encoder_feat = {}
for feature in ['drugName', 'condition']:
    label_encoder_feat[feature] = LabelEncoder()
    df_all[feature] = label_encoder_feat[feature].fit_transform(df_all[feature])

"""The Label Encoder is used to change the categorical values of Drug Names and the conditions in to numerical values for the machine learning modelling. There are 3,667 unique drugs in the dataset that's why One hot encoder is not used as it would generate 3,667 new features and it would be very computationally expensive."""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from sklearn.metrics import confusion_matrix, accuracy_score
from lightgbm import early_stopping
import joblib

# Ensure df_train and df_test are defined and have the necessary columns
# Example: df_train = pd.read_csv('train_data.csv')
# df_test = pd.read_csv('test_data.csv')
target = df_all['Sentiment']
feats = ['condition','usefulCount','day','year','month','count_sent', 'sentiment_value', 'sentiment_clean_ss',
'count_word', 'count_unique_word', 'count_letters', 'count_punctuations',
'count_words_upper', 'count_words_title', 'count_stopwords', 'mean_word_len']

# sub_preds = np.zeros(df_test.shape[0])

# Split the data into train and validation sets
trn_x, test_x, trn_y, test_y = train_test_split(df_all[feats], target, test_size=0.3, random_state=42)

feature_importance_df = pd.DataFrame()
model_file_path = '/content/drive/MyDrive/drug_review_dataset_drugs_com/lgb_model.pkl'

# Check if the model file exists
if os.path.exists(model_file_path):
    print("Loading the pre-trained model...")
    # Load the pre-trained model
    lgb_model = joblib.load(model_file_path)
else:

    # Initialize the classifier
    lgb_model = lgb.LGBMClassifier(
        n_estimators=10000,
        learning_rate=0.1,
        num_leaves=30,
        subsample=0.9,
        max_depth=7,
        reg_alpha=0.1,
        reg_lambda=0.1,
        min_split_gain=0.01,
        min_child_weight=2,
        verbosity=-1,  # Use verbosity for logging, -1 to suppress output
    )

    # Fit the model with early stopping and evaluation set
    lgb_model.fit(trn_x, trn_y)

    # Save the trained model for future use
    joblib.dump(lgb_model, model_file_path)
    print("Model trained and saved!")

# Predict using the trained model
sub_preds = lgb_model.predict(test_x)
cm = confusion_matrix(test_y, sub_preds)
# Optionally, evaluate the model performance
print("Confusion Matrix:")
print(cm)
print("Accuracy:", accuracy_score(test_y, sub_preds))

# # Optionally, get feature importances if needed
# feature_importance_df['feature'] = trn_x.columns
# feature_importance_df['importance'] = clf.feature_importances_
# print("Feature Importances:")

# print(feature_importance_df)

# Display the confusion matrix using seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=lgb_model.classes_, yticklabels=lgb_model.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# hyperparameter tuning
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from sklearn.metrics import confusion_matrix, accuracy_score
from lightgbm import early_stopping
import joblib
from sklearn.model_selection import RandomizedSearchCV
# Define the model file path
model_file_path = '/content/drive/MyDrive/drug_review_dataset_drugs_com/best_lgb_model.pkl'


# Check if the model file exists
if os.path.exists(model_file_path):
    print("Loading the pre-trained model...ca")
    # Load the pre-trained model
    best_model = joblib.load(model_file_path)
else:
    print("Training the model...")
    # If the model doesn't exist, train it

    # Initialize the classifier
    clf = lgb.LGBMClassifier(
        learning_rate=0.1,
        num_leaves=30,
        subsample=0.9,
        max_depth=7,
        reg_alpha=0.1,
        reg_lambda=0.1,
        min_split_gain=0.01,
        min_child_weight=2,
        verbosity=-1  # Suppress verbose output
    )

    # Define the parameter distribution for RandomizedSearchCV, including n_estimators
    param_dist = {
        'n_estimators': [5000, 10000, 15000],  # Varying n_estimators
        'learning_rate': [0.05, 0.1, 0.15],
        'num_leaves': [20, 30, 40, 50],
        'max_depth': [5, 7, 10, -1]
    }

    # Initialize RandomizedSearchCV
    random_search = RandomizedSearchCV(
        estimator=clf,
        param_distributions=param_dist,
        n_iter=10,  # Number of iterations to sample from the parameter space
        scoring='accuracy',
        cv=3,  # Cross-validation folds
        verbose=1,
        n_jobs=-1,  # Use all CPU cores
        random_state=42
    )

    # Fit the randomized search
    random_search.fit(trn_x, trn_y)

    # Best Parameters
    print("Best parameters found: ", random_search.best_params_)
    print("Best accuracy: ", random_search.best_score_)

    # Extract results and plot performance for each set of hyperparameters
    results = pd.DataFrame(random_search.cv_results_)
    results = results[['param_learning_rate', 'param_num_leaves', 'param_max_depth', 'mean_test_score']]

    # Plot performance
    plt.figure(figsize=(10,6))
    for learning_rate in results['param_learning_rate'].unique():
      temp = results[results['param_learning_rate'] == learning_rate]
      plt.plot(temp['param_num_leaves'], temp['mean_test_score'], label=f'Learning rate: {learning_rate}')

    plt.xlabel('Number of Leaves')
    plt.ylabel('Mean Test Accuracy')
    plt.title('Performance vs Number of Leaves for Different Learning Rates')
    plt.legend()
    plt.show()

    # Get the best model
    best_model = random_search.best_estimator_

    # Save the trained model for future use
    joblib.dump(best_model, model_file_path)
    print("Model trained and saved!")



# Evaluate the best model
sub_preds = best_model.predict(test_x)
cm = confusion_matrix(test_y, sub_preds)
print("Confusion Matrix:")
print(cm)
print("Accuracy:", accuracy_score(test_y, sub_preds))

# F1 Score
f1 = f1_score(sub_preds, test_y, average='weighted')  # Adjust 'average' as needed
print(f"F1 Score: {f1:.2f}")

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Plot feature importances
plt.figure(figsize=(10, 6))
plt.barh(trn_x.columns, best_model.feature_importances_)
plt.xlabel('Feature Importance')
plt.title('Feature Importance for Best Model')
plt.show()

"""Dictionary_Sentiment_Analysis"""

# import dictionary data
word_table = pd.read_csv("/content/drive/MyDrive/drug_review_dataset_drugs_com/harvard_emotion_dict.csv")
word_table.head(10)

import re

#Positiv word list
temp_Positiv = []
Positiv_word_list = []
for i in range(0,len(word_table.Positiv)):
    if word_table.iloc[i,2] == "Positiv":
        temp = word_table.iloc[i,0].lower()
        temp1 = re.sub('\d+', '', temp)
        temp2 = re.sub('#', '', temp1)
        temp_Positiv.append(temp2)

Positiv_word_list = list(set(temp_Positiv))
len(temp_Positiv)
len(Positiv_word_list)  #del temp_Positiv

#Negativ word list
temp_Negativ = []
Negativ_word_list = []
for i in range(0,len(word_table.Negativ)):
    if word_table.iloc[i,3] == "Negativ":
        temp = word_table.iloc[i,0].lower()
        temp1 = re.sub('\d+', '', temp)
        temp2 = re.sub('#', '', temp1)
        temp_Negativ.append(temp2)

Negativ_word_list = list(set(temp_Negativ))
len(temp_Negativ)
len(Negativ_word_list)  #del temp_Negativ

# Reverting the label encoding for 'drugName' and 'condition'
for feature in ['drugName', 'condition']:
    df_all[feature] = label_encoder_feat[feature].inverse_transform(df_all[feature])

df_train, df_test = train_test_split(df_all, test_size=0.3, random_state=42)

# counting the positive words
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(vocabulary = Positiv_word_list)
content = df_test['review_clean']
X = vectorizer.fit_transform(content)
f = X.toarray()
f = pd.DataFrame(f)
f.columns=Positiv_word_list
df_test["num_Positiv_word"] = f.sum(axis=1)

# counting the negative words

vectorizer2 = CountVectorizer(vocabulary = Negativ_word_list)
content = df_test['review_clean']
X2 = vectorizer2.fit_transform(content)
f2 = X2.toarray()
f2 = pd.DataFrame(f2)
f2.columns=Negativ_word_list
df_test["num_Negativ_word"] = f2.sum(axis=1)

# decide sentiment by positivity ratio
df_test["Positiv_ratio"] = df_test["num_Positiv_word"]/(df_test["num_Positiv_word"]+df_test["num_Negativ_word"])
df_test["sentiment_by_dic"] = df_test["Positiv_ratio"].apply(lambda x: 1 if (x>=0.5) else (0 if (x<0.5) else 0.5))

df_test.head()

"""Drug Recommendation"""



#normalized the usefulcount by dividing the total number of reviews for that condition

def userful_count(data):
    grouped = data.groupby(['condition']).size().reset_index(name='user_size')
    data = pd.merge(data,grouped,on='condition',how='left')
    return data

df_test =  userful_count(df_test)
df_test['usefulCount'] = df_test['usefulCount']/df_test['user_size']

# Add predictions from deep learning and machine learning models, and sentiment analysis
df_test['deep_pred'] = sub_preds_deep  # Deep learning model predictions
df_test['machine_pred'] = sub_preds  # Lightgbm learning model predictions

# Calculate the total prediction score by combining the different prediction scores, weighted by the 'usefulCount' column
df_test['total_pred'] = (df_test['deep_pred'] + df_test['machine_pred'] + df_test['sentiment_by_dic']) * df_test['usefulCount']
df_test.head()

# Group the data by condition and drug name, and calculate the mean of the total prediction score for each group
df_recommend = df_test.groupby(['condition','drugName']).agg({'total_pred' : ['mean']})

# Sort the dataframe by the mean of total_pred in descending order to prioritize drugs with higher scores
sorted_df = df_recommend.sort_values(('total_pred', 'mean'), ascending=False)
sorted_df.head(40)

# Normalize the 'condition' column in sorted_df to lowercase
sorted_df.index = sorted_df.index.set_levels([sorted_df.index.levels[0].str.lower(), sorted_df.index.levels[1]])

# Update the function to match lowercase condition names
def get_drug_by_condition(sorted_df, condition):
    # Convert input condition to lowercase to match the normalized index
    condition_lower = condition.lower()
    # Get predicted values for the condition
    if condition_lower in sorted_df.index.levels[0]:
        condition_df = sorted_df.loc[condition_lower]
        # Get drug with the highest predicted value
        drug = condition_df[condition_df == condition_df.max()].index.get_level_values('drugName')[0]
        return drug
    else:
        print(f"Condition '{condition}' not found.")
        return None

# Example usage
condition = input("Please enter condition: ")
drug = get_drug_by_condition(sorted_df, condition)
if drug:
    print(f"Drug with highest predicted value for condition '{condition}': {drug}")

df_test.head(
)